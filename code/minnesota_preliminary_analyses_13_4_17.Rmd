---
title: "Preliminary analyses for Minnesota beta diversity"
output:
  pdf_document: default
  html_notebook: default
---

Description: Code for preparing and performing preliminary analysis on Minnesota 
beta diversity  
Author: Eric Le Tortorec  
Date: `r Sys.Date()`  
R version: `r R.Version()$version.string`  

##Table of contents
[Load necessary packages](#load_necessary_packages)  
[Prepare vector data](#prepare_vector_data)  
[Prepare other data](#prepare_other_data)  
[Calculate BBA points per unit](#calcualte_points_per_unit)  
[Create human land-use index with PCA](#human_land_use_pca)  
[Process and calculate human footprint index for each unit](#human_footprint_per_unit)  
[Compare human influence PCA and human footprint](#compare_pca_footprint)  
[Process and calculate forest loss per unit](#forest_loss_per_unit)  
[Prepare bird data](#prepare_bird_data)  
[Calculate beta diversity](#calculate_beta_div)  
[Data exploration](#data_exploration)  
[Analyse beta diversity](#analyse_beta_div)  
[Checking model residuals](#check_model_res)  

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
# set global chunk options
knitr::opts_knit$set(root.dir = normalizePath('/Users/Eric/Dropbox/Eric/Work/JKL/Theses/Matti_Hakkila/paper_4/'))
```

##Load necessary packages {#load_necessary_packages}
```{r, results = 'hide'}
library(reshape2)
library(dplyr)
library(tidyr)
library(readxl)
library(ggplot2)
library(maptools)
library(rgeos)
library(rgdal)
library(raster)
library(gstat)
library(psych)
library(lattice)
```

##Prepare vector data {#prepare_vector_data}
We prepare the vector data by joining all unit-level data together
```{r, results = 'hide', eval = FALSE}
# Read the different unit-level shapefiles
units <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units.shp', 'Units')
units_census <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_Census.shp', 'Units_Census')
units_eco_subsection <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_EcoSubsection.shp', 'Units_EcoSubsection')
units_forest_status <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_ForestStatus.shp', 'Units_ForestStatus')
units_land_fire <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_Landfire.shp', 'Units_Landfire')
units_prism <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_PRISM.shp', 'Units_PRISM')
units_road_density <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_RoadDensity.shp', 'Units_RoadDensity')
units_forest_loss <- readOGR('./data/forest_loss_3_2017/Units_ForestLoss.shp', 'Units_ForestLoss')

# Join attributes of unit- level shapefiles
units_merged <- units
units_merged <- merge(units_merged, units_eco_subsection, by = 'unit')
units_merged <- merge(units_merged, units_census, by = 'unit')
units_merged <- merge(units_merged, units_prism, by = 'unit')
units_merged <- merge(units_merged, units_forest_status, by = 'unit')
units_merged <- merge(units_merged, units_road_density, by = 'unit')
units_merged <- merge(units_merged, units_land_fire, by = 'unit')
units_merged <- merge(units_merged, units_forest_loss, by = 'unit')
units_merged@data$Dens_Minor <- as.numeric(units_merged@data$Dens_Minor)

# Save the joined data as a shapefile
writeOGR(units_merged, './data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/units_merged.shp', 'units_merged', driver = 'ESRI Shapefile', overwrite_layer = T)
```

##Prepare other data {#prepare_other_data}
```{r, results = 'hide'}
forest_status_2 <- raster('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/forest_status/forstat_rast2.tif')
land_fire_3 <- raster('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/landfire/landfire3.tif')
mnn_bba_points <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/bird_data/MNBBA_Surveys_DominantHabitat_Final.shp', 'MNBBA_Surveys_DominantHabitat_Final')
mnn_bba_points@data$Date <- as.Date(mnn_bba_points@data$Date , "%Y/%m/%d")
```

##Calculate BBA points per unit {#calcualte_points_per_unit}
Later on we will need to determine how many forested BBA points there are per 
unit. There are three ways of doing this:

* Reclassify the forest status raster into two classes: forest and non-forest
* Reclassify the land_fire_3 raster into the same to classes
* Reclassify the land cover class of each point (this information is included 
in the BBA data) in the same two classes.

The reclassifications for the last two approaches are such that forests are:

* Lowland Deciduous Forest
* Northern Hardwoods
* Pine Forest
* Boreal Deciduous
* Oak Forest
* Parkland Deciduous Forest
* Boreal Coniferous
* Lowland Coniferous Forest
* Rural Developed Forest
* Urban Developed Forest
* Pine-Oak Barrens
* Oak Savannah

Even though reclassifying the dominant land cover class of the BBA points yields 
the least points, we will use it since it has been measured directly in the 
field. We reclassify the Reclass3_5- column from mnna_bba_points (dominant 
landcover type within 50m of the BBA point, using the reclass3 classification). 
This will be used later on to calculate the number of forested BBA points per 
unit
```{r}
mnn_bba_points@data$forest_bba <- mnn_bba_points@data$Reclass3_5
levels(mnn_bba_points@data$forest_bba) <- list('1' = c("Boreal Coniferous", 
  "Boreal Coniferous_10m", "Boreal Deciduous", "Boreal Deciduous_10m", 
  "Lowland Coniferous Forest", "Lowland Coniferous Forest_10m", 
  "Lowland Deciduous Forest", "Lowland Deciduous Forest_10m", 
  "Northern Hardwoods", "Northern Hardwoods_10m", "Oak Forest", 
  "Oak Forest_10m", "Oak Savannah", "Parkland Deciduous Forest_10m", 
  "Pine Forest", "Pine Forest_10m", "Pine-Oak Barrens", "Pine-Oak Barrens_10m", 
  "Rural Developed Forest_10m", "Urban Developed Forest", 
  "Urban Developed Forest_10m"), '0' = c("Boreal Lowland Grassland", 
  "Boreal Shrub Swamp", "Cropland", "Developed-High Intensity", 
  "Developed-Low Intensity", "Developed-Medium Intensity", "Lowland Herbaceous", 
  "Open Water", "Quarries-Strip Mines-Gravel Pits", "Shrub Swamp", 
  "Upland Grassland", "Upland Native Grassland", "Upland Shrub"))
mnn_bba_points@data$forest_bba <- as.numeric(as.character(mnn_bba_points@data$forest_bba))
```

We then continue by calculating how many unique BBA points fall within each 
unit. Let's count if there are points with duplicated coordinates.

```{r}
coord_counts <- plyr::count(mnn_bba_points@data, c('x', 'y'))
table(coord_counts$freq)
coord_counts_dupl <- coord_counts[coord_counts$freq > 1, ]
```

We can see that the vast majority of points have uniqe coordinates, a few have 
one duplicate, and one is present three times!

Let's continue by inspecting nearest neghbour distances for points with unique 
coordinates.
```{r}
# Select unique points based on coordinates, also sort by date
mnn_bba_points_unique <- mnn_bba_points[order(mnn_bba_points@data$x, 
  mnn_bba_points@data$y, mnn_bba_points@data$Date), ]
mnn_bba_points_unique <- mnn_bba_points_unique[which(!duplicated(mnn_bba_points_unique@data[c('x', 'y')], fromLast = FALSE)), ]

# Calculate distances between points
point_dist_unique <- as.data.frame(pointDistance(mnn_bba_points_unique, lonlat = FALSE))
colnames(point_dist_unique) <- mnn_bba_points_unique@data$ID
rownames(point_dist_unique) <- mnn_bba_points_unique@data$ID

# Calculate minimum distances, but leave zeros out, since they are present in 
# every row and column
point_dist_nn <- sapply(point_dist_unique, FUN = function(x) {min(x[x > 0])})
point_dist_nn <- sort(point_dist_nn)
summary(point_dist_nn)
hist(point_dist_nn, breaks = 20, main = 'Frequencies of nearest neighbour 
  distances between points', 
  xlab = 'Nearest neighbour distance (m)')
```

It's a bit hard to determine a cut-off point since there is a contimuum of 
nearest neighbour values from `r min(point_dist_nn)`m all the way to `r max(point_dist_nn)`m. 
If we look at the smallest distances we can see that there is a small spike at 
the very smallest values (around 10-20m). However, there is a steady stream of 
small frequencies up to 200m. This is a bit odd considering that we would expect 
a smallish frequency of very small distances (points that have been counted 
twice), a gap, and then clearly larger distances between independent points 
(~250m, according to the sampling protocol).
```{r}
hist(point_dist_nn[1:1000], breaks = 20, main = 'Frequencies of nearest neighbour 
  distances between points', xlab = 'Nearest neighbour distance (m)')
```

Since we are using bird counts within a 50m radius, as well as using dominant 
land cover within 50m, we will subset the points so we only include points that 
are at least 100m away from each other. We will include the earlier observation 
from each point pair, and randomy select a point if the dates are the same.
```{r}
# Select points located under 100m from each other
point_dist_nn_over <- data.frame(distance = point_dist_nn[point_dist_nn > 100])
point_dist_nn_over$ID <- as.integer(rownames(point_dist_nn_over))
point_dist_nn_under <- data.frame(distance = point_dist_nn[point_dist_nn < 100])
point_dist_nn_under$ID <- as.integer(rownames(point_dist_nn_under))
point_dist_nn_under <- dplyr::left_join(point_dist_nn_under, 
  mnn_bba_points_unique@data[c('ID', 'Date')], by = 'ID')
point_dist_nn_under <- dplyr::arrange(point_dist_nn_under, distance, Date)

point_dist_nn_under_duplc_dis_date <- point_dist_nn_under[duplicated(point_dist_nn_under[c('distance', 'Date')]) | 
    duplicated(point_dist_nn_under[c('distance', 'Date')], fromLast = TRUE), ]
point_dist_nn_under_duplc_dis <- point_dist_nn_under[!(point_dist_nn_under$ID %in% 
    point_dist_nn_under_duplc_dis_date$ID), ]
point_dist_nn_under_unique_dis <- point_dist_nn_under_duplc_dis[!duplicated(point_dist_nn_under_duplc_dis$distance, 
  fromLast = FALSE), ]

set.seed(7)
point_dist_nn_under_ID <- sapply(unique(point_dist_nn_under_duplc_dis_date$distance), 
  function(x) sample(point_dist_nn_under_duplc_dis_date$ID[point_dist_nn_under_duplc_dis_date$distance == x], 1))
point_dist_nn_under_ID <- c(point_dist_nn_under_ID, point_dist_nn_under_unique_dis$ID)
  
mnn_bba_points_unique_under <- mnn_bba_points_unique[mnn_bba_points_unique@data$ID %in% 
    point_dist_nn_under_ID, ]
mnn_bba_points_unique_over <- mnn_bba_points_unique[mnn_bba_points_unique@data$ID %in% 
    point_dist_nn_over$ID, ]

mnn_bba_points_unique_subset <- spRbind(mnn_bba_points_unique_over, mnn_bba_points_unique_under)
#aaa <- as.data.frame(pointDistance(mnn_bba_points_unique_subset, lonlat = FALSE))
#colnames(aaa) <- mnn_bba_points_unique_subset@data$ID
#rownames(aaa) <- mnn_bba_points_unique_subset@data$ID
#bbb <- sapply(aaa, FUN = function(x) {min(x[x > 0])})
#min(bbb)
#max(bbb)
#dim(mnn_bba_points_unique_subset@data)
```

Let's continue by calculating how many unique, subsetted points there are per 
unit
```{r}
units_merged <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/units_merged.shp', 'units_merged')
# Calculate the number of unique BBA points within each unit
units_points <- over(mnn_bba_points_unique_subset, units_merged)
#units_points <- over(mnn_bba_points_unique, units_merged)
units_points_count <- data.frame(table(units_points$unit))
colnames(units_points_count) <- c('unit', 'point_freq')
units_points_count$unit <- as.numeric(as.character(units_points_count$unit))
units_merged <- merge(units_merged, units_points_count, by = 'unit')
units_merged@data$point_freq[is.na(units_merged@data$point_freq)] <- 0

# Summarise how many unique BBA points there are per unit
point_freq <- as.data.frame(table(units_merged@data$point_freq))
colnames(point_freq) <- c('points per unit', 'freq')
print.data.frame(point_freq)
hist(units_merged@data$point_freq, breaks = 18, xlim = c(0, 20), xlab = 'Number 
of BBA points', main = 'BBA points per unit')
```

There are a total of `r length(mnn_bba_points_unique_subset)` points out of a 
total of `r length(mnn_bba_points)` BBA points in the data. There are a total of 
 `r sum(mnn_bba_points_unique_subset@data$forest_bba)` forested BBA points.

Let's then calculate the number of forested BBA points per unit.
```{r}
# Select forest BBA points
mnn_bba_points_forest <- mnn_bba_points_unique_subset[mnn_bba_points_unique_subset@data$forest_bba == 1, ]

# Calculate the number of BBA points in forested pixels within each unit
units_forest_points <- over(mnn_bba_points_forest, units_merged)
units_forest_points_count <- data.frame(table(units_forest_points$unit))
colnames(units_forest_points_count) <- c('unit', 'forest_point_freq')
units_forest_points_count$unit <- as.numeric(as.character(units_forest_points_count$unit))

units_merged <- merge(units_merged, units_forest_points_count, by = 'unit')
units_merged@data$forest_point_freq[is.na(units_merged@data$forest_point_freq)] <- 0

# Summarise how many unique forested BBA points there are per unit
forest_point_freq <- as.data.frame(table(units_merged@data$forest_point_freq))
colnames(forest_point_freq) <- c('forested points per unit', 'freq')
print.data.frame(forest_point_freq)
hist(units_merged@data$forest_point_freq, breaks = 15, xlim = c(0, 15), xlab = 'Number 
of forested BBA points', main = 'Forested BBA points per unit')
```
We can see that with a minimum of 2 BBA points in forested pixels per unit, we 
have a total of `r nrow(units_merged[units_merged@data$forest_point_freq >= 2, ])` units. 
A minimum of 3 forested BBA points results in `r nrow(units_merged[units_merged@data$forest_point_freq >= 3, ])` units.

##Create human land-use index with PCA {#human_land_use_pca}
Let's continue by selecting land-use variables that describe human land-use.

* sum of people per unit
* density of major highways per unit
* density of minor highways per unit
* density of other roads per unit
* proportion of quarries, strip mines and gravel pits
* proportion of low intensity development
* proportion of medium intensity development
* proportion of high intensity development
* proportion of cropland

```{r}
# Select variables for PCA
units_merged_pca <- dplyr::select(units_merged@data, censusSUM, Dens_Major, 
  Dens_Minor, Dens_Other, HabV15:HabV18, HabV26)

# Print scree plot, showing how many components to include in the PCA
VSS.scree(units_merged_pca, main = "scree plot")
```

3 components should be enough, let's perform the PCA and extract 3 factors
```{r}
# Perform PCA
human_gradient_pca <- principal(units_merged_pca, nfactors = 3, rotate="varimax",
  covar = F)
human_gradient_pca
```

We can see that the first principal component is highly correlated with 
population number, density of major highways and other roads, proportion of low 
intensity development, proportion of medium intensity development and proportion 
of high intensity development. The second principal component is correlated with 
the density of minor highways and croplands, and the third principal component 
with the proportion of quarries, strip mines and gravel pits.

The first component does a good job of summarising many aspects of human 
land-use, and captures 58% of the variation, while the next two are more 
specific and capture 12% of the variation, respectively.

Let's join the first component to the merged data
```{r}
units_merged@data$human_pca <- human_gradient_pca$scores[, 1]
```

##Process and calculate human footprint index for each unit {#human_footprint_per_unit}
We continue by looking into calculating an index describing the intensity of 
the human footprint.

Then we read, clip and reproject the human footprint data so that average values 
per unit can be calculated. The first part of the code below reads, clips and 
reprojects the human footprint data. For some reason raster::projectRaster 
cannot reproject between WGS84 and UTM zone 15, even if the raster has been 
clipped to the spatial limits of zone 15. Thus, the clipped raster is saved as 
a geotiff, and reprojected with gdal in the terminal.
```{r, eval = FALSE}
minnesota <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Minnesota_Outline.shp', 'Minnesota_Outline')
human_footprint_orig <- raster('./data/last_of_the_wild/human_footprint_2/hfp_n_amer/dblbnd.adf')
crs(human_footprint_orig) <- CRS("+init=epsg:4326")

minnesota_extent <- as(extent(minnesota), 'SpatialPolygons')
crs(minnesota_extent) <- crs(minnesota)

minnesota_extent_wgs84 <- spTransform(minnesota_extent, CRS = CRS('+init=epsg:4326'))
human_footprint_minnesota <- crop(human_footprint_orig, minnesota_extent_wgs84)

writeRaster(human_footprint_minnesota, filename = './Data/last_of_the_wild/human_footprint_2/human_footprint_minnesota.tif', overwrite =T)
###gdalwarp -s_srs '+init=epsg:4326' -t_srs '+init=epsg:26915' human_footprint_minnesota.tif human_footprint_utm15n.tif
```

We then read the reprojected data and calculate the average human footprint 
value per unit, and merge it to the unit-level data
```{r, eval = FALSE}
human_footprint <- raster('./data/last_of_the_wild/human_footprint_2/human_footprint_utm15n.tif')
units <- units[order(units@data$unit, decreasing = FALSE), ]

units_hfp <- extract(human_footprint, units, fun = mean, na.rm = T)
units_hfp <- data.frame(unit = seq(1, 617, 1), human_footprint = units_hfp)
write.csv(units_hfp, './data/last_of_the_wild/human_footprint_2/units_hfp.csv', 
  row.names = FALSE)
```

##Compare human influence PCA and human footprint {#compare_pca_footprint}
Before comparing the pca and human footprint values we choose only units with 
at least two forested BBA points.
```{r, results = 'hide'}
# Join human footprint data to units_merged
units_hfp <- read.csv('./data/last_of_the_wild/human_footprint_2/units_hfp.csv')
units_merged <- merge(units_merged, units_hfp, by = 'unit')

# Set minimum number of forested unique BBA points per unit
################
min_points <- 4
################
units_merged_subset <- units_merged[units_merged@data$forest_point_freq >= min_points, ]
```

Then, we print a scatter plot of pca vs. human footprint.
```{r}
plot(units_merged_subset$human_pca, units_merged_subset$human_footprint, xlab = 
    'Human influence principal component', ylab = 'Human footprint index')
```

Not bad! We have a Pearson's correlation coefficient of `r cor(units_merged_subset$human_pca, units_merged_subset$human_footprint, use = 'complete.obs')`, which means that the two 
indices pretty much capture the same variation in the data. The relation breaks 
down slightly at the highest PCA values, but not too badly. It would probably be 
a good idea to go with the human footprint index even though its time period 
does not match the bird data so well (1995 - 2004). The roads, railways, 
population etc. included in the calculation of the index are probably variables 
that won't change very quickly. In any case, the variables used in the PCA are 
not necessarily up to date with the bird data either.

##Process and calculate forest loss per unit {#forest_loss_per_unit}
In addition to the index describing human land use we want to study if forest 
loss has an impact on beta diversity. We have forest loss data from Minnesota, 
which is derived from Hansen et al. 2013 *. The data has proportion 
forest loss between 2001-2014 per unit. Note that forest fires are also 
included! Ed said that data separating the two types of forest loss 
might be available in 6 months - 1 year, but this is too long.    

*Hansen MC, Potapov PV, Moore R, Hancher M, Turubanova SA, Tyukavina A, et 
al. High-Resolution Global Maps of 21st-Century Forest Cover Change. Science. 
2013 Nov 15;342(6160):850–3. 

##Prepare bird data {#prepare_bird_data}
Let's continue by loading the bird data and printing all unique bird species in 
the data.
```{r}
library(readxl)
bird_data_whole <- read_excel('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/bird_data/Homogenization_All_BirdData.xlsx')
sort(unique(bird_data_whole$common))
```

We filter the bird data so that we only include forested BBA points with unique 
coordinates located in units with at least two such points, and leave out all 
unidentified species.
```{r}
# Identify common units between the subsetted units data and the bird data (not 
# all of the units are included in the bird data, unit 617 is missing)
common_units <- dplyr::inner_join(data.frame(unit = units_merged_subset@data$unit), data.frame(unit = unique(bird_data_whole$unit)), by = 'unit')
unique_coord_id <- mnn_bba_points_forest@data[c('ID', 'x', 'y')]
#colnames(bird_data_whole)

bird_points_species <- dplyr::select(bird_data_whole, ID, unit, common, Sum_Inside50m) %>% 
  dplyr::filter(ID %in% unique_coord_id$ID) %>% 
  dplyr::filter(unit %in% common_units$unit) %>% 
  dplyr::filter(!grepl('Unidentified', common)) %>% 
  dplyr::arrange(ID, common)

bird_points_species_wide <- dplyr::select(bird_points_species, -unit) %>% 
  tidyr::spread(ID, Sum_Inside50m)
bird_points_species_wide[is.na(bird_points_species_wide)] <- 0
bird_points_species_wide <- as.data.frame(bird_points_species_wide)
rownames(bird_points_species_wide) <- bird_points_species_wide$common
bird_points_species_wide <- bird_points_species_wide[2:ncol(bird_points_species_wide)]
bird_points_species_wide <- bird_points_species_wide[colSums(bird_points_species_wide) > 0]
```

##Calculate beta diversity {#calculate_beta_div}
Next we calculate beta diversity from the BBA points with the Rao quadratic 
entropy index. The Jost correction is used to correct lower than expected beta 
diversity values. We us the the Rao function, written by Francesco Bello et al. *  

We write a loop to calculate beta diversity between forested BBA points within 
each unit that contains at least 2 such points. We use mean additive beta per 
unit (gamma minus mean alpha)

*De Bello F, Lavergne S, Meynard CN, Lepš J, Thuiller W. The partitioning of 
diversity: showing Theseus a way out of the labyrinth: Theseus and the 
partitioning of diversity. Journal of Vegetation Science. 2010;21(5):992–1000.
```{r}
source('./Code/Rao.r')

beta_unit_list <- vector("list", base::nrow(common_units))
counter <- 0
for (unit in as.vector(common_units$unit)) {
  counter <- counter + 1
  #print(paste0('Unit: ', unit))
  #print(paste0('Counter: ', counter))
  bird_unit <- bird_points_species[bird_points_species$unit == unit, ]
  bird_unit_wide <- dplyr::select(bird_unit, -unit) %>% 
    tidyr::spread(ID, Sum_Inside50m)
  bird_unit_wide[is.na(bird_unit_wide)] <- 0
  bird_unit_wide <- as.data.frame(bird_unit_wide)
  rownames(bird_unit_wide) <- bird_unit_wide$common
  bird_unit_wide <- bird_unit_wide[2:ncol(bird_unit_wide)]
  bird_unit_wide <- bird_unit_wide[colSums(bird_unit_wide) > 0]
  funct_matrix <- matrix(data = 0, nrow = nrow(bird_unit_wide), 
    ncol = nrow(bird_unit_wide))
  phylo_matrix <- matrix(data = 0, nrow = nrow(bird_unit_wide), 
    ncol = nrow(bird_unit_wide))
  bird_div <- Rao(sample = bird_unit_wide, dfunc = funct_matrix, 
    dphyl = phylo_matrix, weight = FALSE, Jost = TRUE, structure = NULL)
  #########
  beta_unit_list[[counter]] <- bird_div$TD$Beta_add
  #########
}

units_beta <- data.frame(beta = unlist(beta_unit_list), unit = common_units$unit)
units_merged_beta <- merge(units_merged, units_beta, by = 'unit')
units_merged_beta <- units_merged_beta[!is.na(units_merged_beta@data$beta), ]
```

```{r, eval = FALSE}
funct_matrix <- matrix(data = 0, nrow = nrow(bird_points_species_wide), 
  ncol = nrow(bird_points_species_wide))
phylo_matrix <- matrix(data = 0, nrow = nrow(bird_points_species_wide), 
  ncol = nrow(bird_points_species_wide))

source("./Code/Rao.r")
bird_div <- Rao(sample = bird_points_species_wide, dfunc = funct_matrix, 
  dphyl = phylo_matrix, weight = FALSE, Jost = TRUE, structure = NULL)
bird_div_beta_add <- as.matrix(bird_div$TD$Pairwise_samples$Beta_add)
bird_div_beta_add[lower.tri(bird_div_beta_add, diag = TRUE)] <- NA
bird_div_beta_add_list <- reshape2::melt(bird_div_beta_add) %>% 
  dplyr::select(unit_1 = Var1, unit_2 = Var2, beta = value) %>% 
  na.omit() %>% dplyr::arrange(unit_1, unit_2)

aaa <- bird_div_beta_add_list[1:10, ]
bbb$hfp_diff <- apply(aaa, 1, FUN = function(x) {print(x[1])})
bbb$hfp_diff <- apply(aaa, 1, FUN = function(x) {print(x[1])})

#bird_div_beta_prop <- as.data.frame(as.matrix(bird_div$TD$Pairwise_samples$Beta_prop))
#bird_div_beta_add[1:10, 1:10]
#bird_div_beta_prop[1:10, 1:8]
#bird_div_alpha <- data.frame(alpha = bird_div$TD$Alpha)
#bird_div_alpha$ID <- as.integer(rownames(bird_div_alpha))
```

##Data exploration {#data_exploration}
Before starting the analyses we do some data exploration to make sure we don't 
have outliers, colinearity etc. These explanatory analyses are from Zuur et. al 
2010 *  

*Zuur AF, Ieno EN, Elphick CS. A protocol for data exploration to avoid common 
statistical problems: Data exploration. Methods in Ecology and Evolution. 2010 
Mar;1(1):3–14. 

```{r}
# Define explanatory variables
explanatory_variables <- dplyr::select(units_merged_beta@data, 
  'Mean_temperature' = tempMN, 'Mean_precipitation' = precMN, 
  'Forest_loss' = allV1, 'Forest_point_freq' = forest_point_freq, 
  'Human_footprint' = human_footprint)
```

1. Outliers
```{r}
explanatory_variables_long <- tidyr::gather(explanatory_variables)

ggplot(explanatory_variables_long, aes(factor(0),value)) +
  geom_boxplot() +  facet_wrap(~key, scales = "free", ncol = 
      length(unique(explanatory_variables_long$key))) + 
  theme(axis.text.x=element_blank(), axis.title.x=element_blank(), 
    axis.title.y = element_blank())
```

We can see that there is one potential outlier in the forest loss variable. This 
is from unit number 38. Looking at the forest loss layer shows that the unit in 
question is right at the centre of the 2011 Pagami Creek fire, which covered 
almost half of the area of the unit (and a fifth of unit 38). In addition, units 
12 and 559, located northeast from Pagami creek seems to be covered by a forest 
fire, most probably the 2007 Ham Lake fire. We should consider leaving these out.

The units with the highest forest loss values are:
```{r}
dplyr::select(units_merged_beta@data, unit, 'Forest_loss' = allV1) %>% 
  dplyr::arrange(desc(Forest_loss)) %>% head(n = 10)
```

Another potential outlier is unit 115 with a total of 18 forested BBA points. 
Let's print the units with the highest numbers of forested BBA points:
```{r}
dplyr::select(units_merged_beta@data, unit, 'Forest_point_freq' = forest_point_freq) %>% 
  dplyr::arrange(desc(Forest_point_freq)) %>% head(n = 10)
```

Increased forest point frequency is associated with increase beta diversity 
values, which needs to be considered in later analyses.

2. Check reponse variable for excess of zeros
```{r}
hist(units_merged_beta@data$beta, main = 'Distribution of beta values', xlab = 'Mean beta per unit')
```

We shouldn't have problems here. Zeros don't dominate the data, and the beta 
diversity values are more or less normally distributed.

3. Colinearity of explanatory variables
```{r, echo = FALSE, results = 'hide'}
# Functions for printing pair plots 
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- cor(x, y, method="pearson")
  txt <- format(c(r, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = 1.5)
}
```

```{r, fig.width = 8, fig.height = 8}
# Pair plots of explanatory variables
pairs(explanatory_variables, cex.labels = 1.2, font.labels=1.6, 
  diag.panel=panel.hist, upper.panel= panel.cor)
```

```{r}
source('./code/HighstatLib.r')
corvif(explanatory_variables)
```

We can see that there is a strongish correlation between mean temperature and 
human footprint (probably caused by a south - north gradient of human impact). 
However, the variance inflation factor (VIF) is a little bit more than two, 
which is not a cause for great concern.

4. Relationships between response and explanatory variables
```{r}
# Explanatory variables in vector format
x <- as.vector(as.matrix(explanatory_variables))
# Response variable in vector format, repeat once for each explanatory variable
y <- rep(units_merged_beta@data$beta, length(names(explanatory_variables)))
# Explanatory variable ID's as factors
x_id <- factor(rep(names(explanatory_variables), each = length(units_merged_beta@data$beta)))

# Plot y vs x, and use a loess smoother to give some idea of the relation
xyplot(y ~ x | x_id, col = 1,
  strip = function(bg = 'white', ...) strip.default(bg = 'white', ...),
  scales = list(alternating = T,
                x = list(relation = "free"),
                y = list(relation = "same")),
  xlab = "Explanatory variables",
  par.strip.text = list(cex = 0.8),
  ylab = "Mean beta diversity per unit",
  panel = function(x, y, subscripts, ...){
    panel.grid(h = -1, v = 2)
    panel.points(x, y, col = 1, pch = 16)
    panel.loess(x, y, col = 1, lwd = 2)
    })
```

There are two interesting relations. First, the outlier in forest loss really 
sticks out. Also, there is a super clear pattern of increasing mean beta 
diversity per unit with an increasing number of forested BBA points per unit.

Let's drop the four units clearly impacted by forest fires. Since beta diversity 
values are calculated within units we can just drop them, instead of having to 
recalculate diversity measures.
```{r}
units_merged_beta_subset <- units_merged_beta[!(units_merged_beta@data$unit %in% 
    c(39, 12, 38, 559)), ]
```

##Analyse beta diversity {#analyse_beta_div}
We then continue by starting to construct a model where the response variable is 
mean beta diversity per unit, and the explanatory variables are, for example, 
human footprint, forest loss etc. We also take the number of forest points per 
unit into account as a covariate.

```{r}
model_variables <- dplyr::select(units_merged_beta_subset@data, beta, 
  'mean_temp' = tempMN, 'mean_prec' = precMN, 
  'forest_loss' = allV1, 'forest_point_freq' = forest_point_freq, 
  'human_footprint' = human_footprint)

m <- lm(beta ~ human_footprint + forest_loss + mean_temp + mean_prec + 
    forest_point_freq, data = model_variables)
summary(m)
```

##Checking model residuals {#check_model_res}
1. Homogeneity of residuals
```{r}
#get unstandardized predicted and residual values
unstandardizedPredicted <- predict(m)
unstandardizedResiduals <- resid(m)
#get standardized values
standardizedPredicted <- (unstandardizedPredicted - mean(unstandardizedPredicted)) / sd(unstandardizedPredicted)
standardizedResiduals <- (unstandardizedResiduals - mean(unstandardizedResiduals)) / sd(unstandardizedResiduals)
#create standardized residuals plot
plot(standardizedPredicted, standardizedResiduals, main = "Standardized Residuals Plot", xlab = "Standardized Predicted Values", ylab = "Standardized Residuals")
#add horizontal line
abline(0,0)
```

2. Normaility of residuals
```{r}
hist(standardizedResiduals, freq = FALSE, main = 'Histogram of model residuals', xlab = 'Residuals')
curve(dnorm, add = TRUE)
#get probability distribution for residuals
probDist <- pnorm(standardizedResiduals)
#create PP plot
plot(ppoints(length(standardizedResiduals)), sort(probDist), main = "PP Plot", xlab = "Observed Probability", ylab = "Expected Probability")
#add diagonal line
abline(0,1)
```

3. Independence of the response variable

Let's see how the semivariance of the residuals change over physical distance. 
```{r, eval = FALSE}
# Grab unit coordinates, add unit names to them, join to residuals data, 
# create semivariogram 
coordinates(units_merged_beta_subset)


m_resid_x_y <- data.frame(unit = names(m$residuals), resid = m$residuals) %>% 
  dplyr::full_join(bird_div_alpha, by = 'ID')


m_resid_x_y <- dplyr::full_join(unique_coord_id, bird_div_alpha, by = 'ID') %>% 
  filter(!is.na(alpha))
bird_data_gstat <- gstat(id = "alpha", formula = alpha ~ x + y, location = ~ x + y, 
  data = bird_data_alpha)
bird_data_variogram <- variogram(bird_data_gstat, width = ((10000) / 20), 
  cutoff = (10000))
bird_data_variogram
plot(bird_data_variogram, main = 'Semivariogram of bird alpha diversity', 
  xlab = 'Distance (m)')
```

...to be continued...

Options to study human influence vs. beta div
-Individual pairwise beta diversities (a lot of them!):
  *explain difference per pair with differences in explanatory variables BUT we 
  are dealing with individual points, not units. It does not seem sensible to 
  look at differences between units, but between the surroundings of points...
  *take units into account as random effects (but there are usually two units 
  per pair, do we just take both into account?)
  *need to take distance into account
-Mean beta per unit (additive or proportional)
  explain mean beta per unit with explanatory variables per unit
-