---
title: "Preliminary analyses for Minnesota beta diversity"
output:
  pdf_document: default
  html_notebook: default
---

Description: Code for preparing and performing preliminary analysis on Minnesota 
beta diversity  
Author: Eric Le Tortorec  
Date: `r Sys.Date()`  
R version: `r R.Version()$version.string`  

##Table of contents
[Load necessary packages](#load_necessary_packages)  
[Prepare vector data](#prepare_vector_data)  
[Prepare other data](#prepare_other_data)  
[Calculate BBA points per unit](#calcualte_points_per_unit)  
[Create human land-use index with PCA](#human_land_use_pca)  
[Process and calculate human footprint index for each unit](#human_footprint_per_unit)  
[Compare human influence PCA and human footprint](#compare_pca_footprint)  
[Process and calculate forest loss per unit](#forest_loss_per_unit)  
[Prepare bird data](#prepare_bird_data)  
[Calculate alpha diversity](#calculate_alpha_div)  
[Calculate beta diversity](#calculate_beta_div)  
[Data exploration](#data_exploration)  
[Analyse beta diversity](#analyse_beta_div)  

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
# set global chunk options
knitr::opts_knit$set(root.dir = normalizePath('/Users/Eric/Dropbox/Eric/Work/JKL/Theses/Matti_Hakkila/paper_4/'))
```

##Load necessary packages {#load_necessary_packages}
```{r, results = 'hide'}
library(dplyr)
library(tidyr)
library(readxl)
library(ggplot2)
library(maptools)
library(rgeos)
library(rgdal)
library(raster)
library(gstat)
library(psych)
```

##Prepare vector data {#prepare_vector_data}
We prepare the vector data by joining all unit-level data together
```{r, results = 'hide', eval = FALSE}
# Read the different unit-level shapefiles
units <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units.shp', 'Units')
units_census <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_Census.shp', 'Units_Census')
units_eco_subsection <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_EcoSubsection.shp', 'Units_EcoSubsection')
units_forest_status <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_ForestStatus.shp', 'Units_ForestStatus')
units_land_fire <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_Landfire.shp', 'Units_Landfire')
units_prism <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_PRISM.shp', 'Units_PRISM')
units_road_density <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_RoadDensity.shp', 'Units_RoadDensity')
units_forest_loss <- readOGR('./data/forest_loss_3_2017/Units_ForestLoss.shp', 'Units_ForestLoss')

# Join attributes of unit- level shapefiles
units_merged <- units
units_merged <- merge(units_merged, units_eco_subsection, by = 'unit')
units_merged <- merge(units_merged, units_census, by = 'unit')
units_merged <- merge(units_merged, units_prism, by = 'unit')
units_merged <- merge(units_merged, units_forest_status, by = 'unit')
units_merged <- merge(units_merged, units_road_density, by = 'unit')
units_merged <- merge(units_merged, units_land_fire, by = 'unit')
units_merged <- merge(units_merged, units_forest_loss, by = 'unit')
units_merged@data$Dens_Minor <- as.numeric(units_merged@data$Dens_Minor)

# Save the joined data as a shapefile
writeOGR(units_merged, './data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/units_merged.shp', 'units_merged', driver = 'ESRI Shapefile', overwrite_layer = T)
```

##Prepare other data {#prepare_other_data}
```{r, results = 'hide'}
forest_status_2 <- raster('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/forest_status/forstat_rast2.tif')
land_fire_3 <- raster('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/landfire/landfire3.tif')
mnn_bba_points <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/bird_data/MNBBA_Surveys_DominantHabitat_Final.shp', 'MNBBA_Surveys_DominantHabitat_Final')
mnn_bba_points@data$Date <- as.Date(mnn_bba_points@data$Date , "%Y/%m/%d")
```

##Calculate BBA points per unit {#calcualte_points_per_unit}
Later on we will need to determine how many forested BBA points there are per 
unit. There are three ways of doing this:

* Reclassify the forest status raster into two classes: forest and non-forest
* Reclassify the land_fire_3 raster into the same to classes
* Reclassify the land cover class of each point (this information is included 
in the BBA data) in the same two classes.

The reclassifications for the last two approaches are such that forests are:

* Lowland Deciduous Forest
* Northern Hardwoods
* Pine Forest
* Boreal Deciduous
* Oak Forest
* Parkland Deciduous Forest
* Boreal Coniferous
* Lowland Coniferous Forest
* Rural Developed Forest
* Urban Developed Forest
* Pine-Oak Barrens
* Oak Savannah

Even though reclassifying the dominant land cover class of the BBA points yields 
the least points, we will use it since it has been measured directly in the 
field. We reclassify the Reclass3_5- column from mnna_bba_points (dominant 
landcover type within 50m of the BBA point, using the reclass3 classification). 
This will be used later on to calculate the number of forested BBA points per 
unit
```{r}
mnn_bba_points@data$forest_bba <- mnn_bba_points@data$Reclass3_5
levels(mnn_bba_points@data$forest_bba) <- list('1' = c("Boreal Coniferous", 
  "Boreal Coniferous_10m", "Boreal Deciduous", "Boreal Deciduous_10m", 
  "Lowland Coniferous Forest", "Lowland Coniferous Forest_10m", 
  "Lowland Deciduous Forest", "Lowland Deciduous Forest_10m", 
  "Northern Hardwoods", "Northern Hardwoods_10m", "Oak Forest", 
  "Oak Forest_10m", "Oak Savannah", "Parkland Deciduous Forest_10m", 
  "Pine Forest", "Pine Forest_10m", "Pine-Oak Barrens", "Pine-Oak Barrens_10m", 
  "Rural Developed Forest_10m", "Urban Developed Forest", 
  "Urban Developed Forest_10m"), '0' = c("Boreal Lowland Grassland", 
  "Boreal Shrub Swamp", "Cropland", "Developed-High Intensity", 
  "Developed-Low Intensity", "Developed-Medium Intensity", "Lowland Herbaceous", 
  "Open Water", "Quarries-Strip Mines-Gravel Pits", "Shrub Swamp", 
  "Upland Grassland", "Upland Native Grassland", "Upland Shrub"))
mnn_bba_points@data$forest_bba <- as.numeric(as.character(mnn_bba_points@data$forest_bba))
```

We then continue by calculating how many unique BBA points fall within each 
unit. Let's count if there are points with duplicated coordinates.

```{r}
coord_counts <- plyr::count(mnn_bba_points@data, c('x', 'y'))
table(coord_counts$freq)
coord_counts_dupl <- coord_counts[coord_counts$freq > 1, ]
```

We can see that the vast majority of points have uniqe coordinates, a few have 
one duplicate, and one is present three times!

Let's continue by inspecting nearest neghbour distances for points with unique 
coordinates.
```{r}
# Select unique points based on coordinates, also sort by date
mnn_bba_points_unique <- mnn_bba_points[order(mnn_bba_points@data$x, 
  mnn_bba_points@data$y, mnn_bba_points@data$Date), ]
mnn_bba_points_unique <- mnn_bba_points_unique[which(!duplicated(mnn_bba_points_unique@data[c('x', 'y')], fromLast = FALSE)), ]

# Calculate distances between points
point_dist_unique <- as.data.frame(pointDistance(mnn_bba_points_unique, lonlat = FALSE))
colnames(point_dist_unique) <- mnn_bba_points_unique@data$ID
rownames(point_dist_unique) <- mnn_bba_points_unique@data$ID

# Calculate minimum distances, but leave zeros out, since they are present in 
# every row and column
point_dist_nn <- sapply(point_dist_unique, FUN = function(x) {min(x[x > 0])})
point_dist_nn <- sort(point_dist_nn)
summary(point_dist_nn)
hist(point_dist_nn, breaks = 20, main = 'Frequencies of nearest neighbour 
  distances between points', 
  xlab = 'Nearest neighbour distance (m)')
```

It's a bit hard to determine a cut-off point since there is a contimuum of 
nearest neighbour values from `r min(point_dist_nn)`m all the way to `r max(point_dist_nn)`m. 
If we look at the smallest distances we can see that there is a small spike at 
the very smallest values (around 10-20m). However, there is a steady stream of 
small frequencies up to 200m. This is a bit odd considering that we would expect 
a smallish frequency of very small distances (points that have been counted 
twice), a gap, and then clearly larger distances between independent points 
(~250m, according to the sampling protocol).
```{r}
hist(point_dist_nn[1:1000], breaks = 20, main = 'Frequencies of nearest neighbour 
  distances between points', xlab = 'Nearest neighbour distance (m)')
```

Since we are using bird counts within a 50m radius, as well as using dominant 
land cover within 50m, we will subset the points so we only include points that 
are at least 100m away from each other. We will include the earlier observation 
from each point pair, and randomy select a point if the dates are the same.
```{r}
# Select points located under 100m from each other
point_dist_nn_over <- data.frame(distance = point_dist_nn[point_dist_nn > 100])
point_dist_nn_over$ID <- as.integer(rownames(point_dist_nn_over))
point_dist_nn_under <- data.frame(distance = point_dist_nn[point_dist_nn < 100])
point_dist_nn_under$ID <- as.integer(rownames(point_dist_nn_under))
point_dist_nn_under <- dplyr::left_join(point_dist_nn_under, 
  mnn_bba_points_unique@data[c('ID', 'Date')], by = 'ID')
point_dist_nn_under <- dplyr::arrange(point_dist_nn_under, distance, Date)

point_dist_nn_under_duplc_dis_date <- point_dist_nn_under[duplicated(point_dist_nn_under[c('distance', 'Date')]) | 
    duplicated(point_dist_nn_under[c('distance', 'Date')], fromLast = TRUE), ]
point_dist_nn_under_duplc_dis <- point_dist_nn_under[!(point_dist_nn_under$ID %in% 
    point_dist_nn_under_duplc_dis_date$ID), ]
point_dist_nn_under_unique_dis <- point_dist_nn_under_duplc_dis[!duplicated(point_dist_nn_under_duplc_dis$distance, 
  fromLast = FALSE), ]

set.seed(7)
point_dist_nn_under_ID <- sapply(unique(point_dist_nn_under_duplc_dis_date$distance), 
  function(x) sample(point_dist_nn_under_duplc_dis_date$ID[point_dist_nn_under_duplc_dis_date$distance == x], 1))
point_dist_nn_under_ID <- c(point_dist_nn_under_ID, point_dist_nn_under_unique_dis$ID)
  
mnn_bba_points_unique_under <- mnn_bba_points_unique[mnn_bba_points_unique@data$ID %in% 
    point_dist_nn_under_ID, ]
mnn_bba_points_unique_over <- mnn_bba_points_unique[mnn_bba_points_unique@data$ID %in% 
    point_dist_nn_over$ID, ]

mnn_bba_points_unique_subset <- spRbind(mnn_bba_points_unique_over, mnn_bba_points_unique_under)
#aaa <- as.data.frame(pointDistance(mnn_bba_points_unique_subset, lonlat = FALSE))
#colnames(aaa) <- mnn_bba_points_unique_subset@data$ID
#rownames(aaa) <- mnn_bba_points_unique_subset@data$ID
#bbb <- sapply(aaa, FUN = function(x) {min(x[x > 0])})
#min(bbb)
#max(bbb)
#dim(mnn_bba_points_unique_subset@data)
```

Let's continue by calculating how many unique, subsetted points there are per 
unit
```{r}
units_merged <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/units_merged.shp', 'units_merged')
# Calculate the number of unique BBA points within each unit
units_points <- over(mnn_bba_points_unique_subset, units_merged)
#units_points <- over(mnn_bba_points_unique, units_merged)
units_points_count <- data.frame(table(units_points$unit))
colnames(units_points_count) <- c('unit', 'point_freq')
units_points_count$unit <- as.numeric(as.character(units_points_count$unit))
units_merged <- merge(units_merged, units_points_count, by = 'unit')
units_merged@data$point_freq[is.na(units_merged@data$point_freq)] <- 0

# Summarise how many unique BBA points there are per unit
point_freq <- as.data.frame(table(units_merged@data$point_freq))
colnames(point_freq) <- c('points per unit', 'freq')
print.data.frame(point_freq)
hist(units_merged@data$point_freq, breaks = 18, xlim = c(0, 20), xlab = 'Number 
of BBA points', main = 'BBA points per unit')
```

There are a total of `r length(mnn_bba_points_unique_subset)` points out of a 
total of `r length(mnn_bba_points)` BBA points in the data. There are a total of 
 `r sum(mnn_bba_points_unique_subset@data$forest_bba)` forested BBA points.

Let's then calculate the number of forested BBA points per unit.
```{r}
# Select forest BBA points
mnn_bba_points_forest <- mnn_bba_points_unique_subset[mnn_bba_points_unique_subset@data$forest_bba == 1, ]

# Calculate the number of BBA points in forested pixels within each unit
units_forest_points <- over(mnn_bba_points_forest, units_merged)
units_forest_points_count <- data.frame(table(units_forest_points$unit))
colnames(units_forest_points_count) <- c('unit', 'forest_point_freq')
units_forest_points_count$unit <- as.numeric(as.character(units_forest_points_count$unit))

units_merged <- merge(units_merged, units_forest_points_count, by = 'unit')
units_merged@data$forest_point_freq[is.na(units_merged@data$forest_point_freq)] <- 0

# Summarise how many unique forested BBA points there are per unit
forest_point_freq <- as.data.frame(table(units_merged@data$forest_point_freq))
colnames(forest_point_freq) <- c('forested points per unit', 'freq')
print.data.frame(forest_point_freq)
hist(units_merged@data$forest_point_freq, breaks = 15, xlim = c(0, 15), xlab = 'Number 
of forested BBA points', main = 'Forested BBA points per unit')
```
We can see that with a minimum of 2 BBA points in forested pixels per unit, we 
have a total of `r nrow(units_merged[units_merged@data$forest_point_freq >= 2, ])` units.

##Create human land-use index with PCA {#human_land_use_pca}
Let's continue by selecting land-use variables that describe human land-use.

* sum of people per unit
* density of major highways per unit
* density of minor highways per unit
* density of other roads per unit
* proportion of quarries, strip mines and gravel pits
* proportion of low intensity development
* proportion of medium intensity development
* proportion of high intensity development
* proportion of cropland

```{r}
# Select variables for PCA
units_merged_pca <- dplyr::select(units_merged@data, censusSUM, Dens_Major, 
  Dens_Minor, Dens_Other, HabV15:HabV18, HabV26)

# Print scree plot, showing how many components to include in the PCA
VSS.scree(units_merged_pca, main = "scree plot")
```

3 components should be enough, let's perform the PCA and extract 3 factors
```{r}
# Perform PCA
human_gradient_pca <- principal(units_merged_pca, nfactors = 3, rotate="varimax",
  covar = F)
human_gradient_pca
```

We can see that the first principal component is highly correlated with 
population number, density of major highways and other roads, proportion of low 
intensity development, proportion of medium intensity development and proportion 
of high intensity development. The second principal component is correlated with 
the density of minor highways and croplands, and the third principal component 
with the proportion of quarries, strip mines and gravel pits.

The first component does a good job of summarising many aspects of human 
land-use, and captures 58% of the variation, while the next two are more 
specific and capture 12% of the variation, respectively.

Let's join the first component to the merged data
```{r}
units_merged@data$human_pca <- human_gradient_pca$scores[, 1]
```

##Process and calculate human footprint index for each unit {#human_footprint_per_unit}
We continue by looking into calculating an index describing the intensity of 
the human footprint.

Then we read, clip and reproject the human footprint data so that average values 
per unit can be calculated. The first part of the code below reads, clips and 
reprojects the human footprint data. For some reason raster::projectRaster 
cannot reproject between WGS84 and UTM zone 15, even if the raster has been 
clipped to the spatial limits of zone 15. Thus, the clipped raster is saved as 
a geotiff, and reprojected with gdal in the terminal.
```{r, eval = FALSE}
minnesota <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Minnesota_Outline.shp', 'Minnesota_Outline')
human_footprint_orig <- raster('./data/last_of_the_wild/human_footprint_2/hfp_n_amer/dblbnd.adf')
crs(human_footprint_orig) <- CRS("+init=epsg:4326")

minnesota_extent <- as(extent(minnesota), 'SpatialPolygons')
crs(minnesota_extent) <- crs(minnesota)

minnesota_extent_wgs84 <- spTransform(minnesota_extent, CRS = CRS('+init=epsg:4326'))
human_footprint_minnesota <- crop(human_footprint_orig, minnesota_extent_wgs84)

writeRaster(human_footprint_minnesota, filename = './Data/last_of_the_wild/human_footprint_2/human_footprint_minnesota.tif', overwrite =T)
###gdalwarp -s_srs '+init=epsg:4326' -t_srs '+init=epsg:26915' human_footprint_minnesota.tif human_footprint_utm15n.tif
```

We then read the reprojected data and calculate the average human footprint 
value per unit, and merge it to the unit-level data
```{r, eval = FALSE}
human_footprint <- raster('./data/last_of_the_wild/human_footprint_2/human_footprint_utm15n.tif')
units <- units[order(units@data$unit, decreasing = FALSE), ]

units_hfp <- extract(human_footprint, units, fun = mean, na.rm = T)
units_hfp <- data.frame(unit = seq(1, 617, 1), human_footprint = units_hfp)
write.csv(units_hfp, './data/last_of_the_wild/human_footprint_2/units_hfp.csv', 
  row.names = FALSE)
```

##Compare human influence PCA and human footprint {#compare_pca_footprint}
Before comparing the pca and human footprint values we choose only units with 
at least two forested BBA points.
```{r, results = 'hide'}
# Join human footprint data to units_merged
units_hfp <- read.csv('./data/last_of_the_wild/human_footprint_2/units_hfp.csv')
units_merged <- merge(units_merged, units_hfp, by = 'unit')

# Select units that have at least 2 forested unique BBA points in them
min_points <- 2
units_merged_subset <- units_merged[units_merged@data$forest_point_freq >= min_points, ]
```

Then, we print a scatter plot of pca vs. human footprint.
```{r}
plot(units_merged_subset$human_pca, units_merged_subset$human_footprint, xlab = 
    'Human influence principal component', ylab = 'Human footprint index')
```

Not bad! We have a Pearson's correlation coefficient of `r cor(units_merged_subset$human_pca, units_merged_subset$human_footprint, use = 'complete.obs')`, which means that the two 
indices pretty much capture the same variation in the data. The relation breaks 
down slightly at the highest PCA values, but not too badly. It would probably be 
a good idea to go with the human footprint index even though its time period 
does not match the bird data so well (1995 - 2004). The roads, railways, 
population etc. included in the calculation of the index are probably variables 
that won't change very quickly. In any case, the variables used in the PCA are 
not necessarily up to date with the bird data either.

##Process and calculate forest loss per unit {#forest_loss_per_unit}
In addition to the index describing human land use we want to study if forest 
loss has an impact on beta diversity. We have forest loss data from Minnesota, 
which is derived from Hansen et al. 2013 *. The data has proportion 
forest loss between 2001-2014 per unit. Note that forest fires are also 
included! Ed said that data separating the two types of forest loss 
might be available in 6 months - 1 year, but this is too long. Let's use the 
data we have available and see if forest loss is correlated with human pressure.  

*Hansen MC, Potapov PV, Moore R, Hancher M, Turubanova SA, Tyukavina A, et 
al. High-Resolution Global Maps of 21st-Century Forest Cover Change. Science. 
2013 Nov 15;342(6160):850–3. 

```{r}
plot(units_merged_subset$human_footprint, units_merged_subset$allV1, ylab = 
    'Proportion forest loss 2001-2014', xlab = 'Human footprint index')
```

It seems ok. There is a slight negative trend, but nothing super clear. The 
Pearson's correlation coefficient is `r cor(units_merged_subset$human_footprint, units_merged_subset$allV1, use = 'complete.obs')`.

##Prepare bird data {#prepare_bird_data}
Let's continue by loading the bird data and printing all unique bird species in 
the data.
```{r}
library(readxl)
bird_data_whole <- read_excel('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/bird_data/Homogenization_All_BirdData.xlsx')
sort(unique(bird_data_whole$common))
```

We filter the bird data so that we only include forested BBA points with unique 
coordinates, and leave out all unidentified species. We then calculate the 
alpha diversity for each BBA point.
```{r}
unique_coord_id <- mnn_bba_points_forest@data[c('ID', 'x', 'y')]
colnames(bird_data_whole)
bird_points_species <- dplyr::select(bird_data_whole, ID, unit, common, Sum_Inside50m) %>% 
  dplyr::filter(!grepl('Unidentified', common)) %>% 
  dplyr::filter(ID %in% unique_coord_id$ID) %>%
  dplyr::arrange(ID, common)

bird_points_species_wide <- dplyr::select(bird_points_species, -unit) %>% 
  tidyr::spread(ID, Sum_Inside50m)
bird_points_species_wide[is.na(bird_points_species_wide)] <- 0
bird_points_species_wide <- as.data.frame(bird_points_species_wide)
rownames(bird_points_species_wide) <- bird_points_species_wide$common
bird_points_species_wide <- bird_points_species_wide[2:ncol(bird_points_species_wide)]
bird_points_species_wide <- bird_points_species_wide[colSums(bird_points_species_wide) > 0]
```

##Calculate alpha diversity {#calculate_alpha_div}
Next we calculate alpha diversity of BBA points with the Rao quadratic entropy 
index. The Jost correction is used to correct lower than expected beta diversity 
values. We us the the Rao function, written by Francesco Bello et al. *  

*De Bello F, Lavergne S, Meynard CN, Lepš J, Thuiller W. The partitioning of 
diversity: showing Theseus a way out of the labyrinth: Theseus and the 
partitioning of diversity. Journal of Vegetation Science. 2010;21(5):992–1000.
```{r}
# It seems like the functional and phylogenetic matrices are compulsory. At this 
# point we don't have such things, so I created empty matrices to get the 
# script to work.
funct_matrix <- matrix(data = 0, nrow = nrow(bird_points_species_wide), 
  ncol = nrow(bird_points_species_wide))
phylo_matrix <- matrix(data = 0, nrow = nrow(bird_points_species_wide), 
  ncol = nrow(bird_points_species_wide))

source("./Code/Rao.r")
bird_div <- Rao(sample = bird_points_species_wide, dfunc = funct_matrix, 
  dphyl = phylo_matrix, weight = FALSE, Jost = TRUE, structure = NULL)
bird_div_alpha <- data.frame(alpha = bird_div$TD$Alpha)
bird_div_alpha$ID <- as.integer(rownames(bird_div_alpha))
```

##Calculate beta diversity {#calculate_beta_div}
The next step is writing a loop to calculate beta diversity between forested 
BBA points within each unit that contains at least 2 such points. We use mean 
additive beta per unit (gamma minus mean alpha)
```{r}
source('./Code/Rao.r')

# Identify common units between the subsetted units data and the bird data (not 
# all of the units are included in the bird data)
common_units <- dplyr::inner_join(data.frame(unit = units_merged_subset@data$unit), data.frame(unit = unique(bird_data_whole$unit)), by = 'unit')
beta_unit_list <- vector("list", base::nrow(common_units))

counter <- 0
for (unit in as.vector(common_units$unit)) {
  counter <- counter + 1
  #print(paste0('Unit: ', unit))
  #print(paste0('Counter: ', counter))
  bird_unit <- bird_points_species[bird_points_species$unit == unit, ]
  bird_unit_wide <- dplyr::select(bird_unit, -unit) %>% 
    tidyr::spread(ID, Sum_Inside50m)
  bird_unit_wide[is.na(bird_unit_wide)] <- 0
  bird_unit_wide <- as.data.frame(bird_unit_wide)
  rownames(bird_unit_wide) <- bird_unit_wide$common
  bird_unit_wide <- bird_unit_wide[2:ncol(bird_unit_wide)]
  bird_unit_wide <- bird_unit_wide[colSums(bird_unit_wide) > 0]
  funct_matrix <- matrix(data = 0, nrow = nrow(bird_unit_wide), 
    ncol = nrow(bird_unit_wide))
  phylo_matrix <- matrix(data = 0, nrow = nrow(bird_unit_wide), 
    ncol = nrow(bird_unit_wide))
  bird_div <- Rao(sample = bird_unit_wide, dfunc = funct_matrix, 
    dphyl = phylo_matrix, weight = FALSE, Jost = TRUE, structure = NULL)
  beta_unit_list[[counter]] <- bird_div$TD$Beta_add
}

units_beta <- data.frame(beta = unlist(beta_unit_list), unit = common_units$unit)
units_merged <- merge(units_merged, units_beta, by = 'unit')
units_merged_beta <- units_merged[!is.na(units_merged@data$beta), ]
```

##Data exploration {#data_exploration}
Before starting the analyses we do some data exploration to make sure we don't 
have outliers, colinearity etc. These explanatory analyses are from Zuur et. al 
2010 *  

*Zuur AF, Ieno EN, Elphick CS. A protocol for data exploration to avoid common statistical problems: Data exploration. Methods in Ecology and Evolution. 2010 Mar;1(1):3–14. 


1. Outliers
```{r}
explanatory_variables_long <- dplyr::select(units_merged_beta@data, 
  'Mean temperature' = tempMN, 'Mean precipitation' = precMN, 
  'Forest loss' = allV1, 'Forest point freq' = forest_point_freq, 
  'Human footprint' = human_footprint) %>% tidyr::gather()

ggplot(explanatory_variables_long, aes(factor(0),value)) +
  geom_boxplot() +  facet_wrap(~key, scales = "free", ncol = 
      length(unique(explanatory_variables_long$key))) + 
  theme(axis.text.x=element_blank(), axis.title.x=element_blank(), 
    axis.title.y = element_blank())
```

We can see that there is one potential outlier in the forest loss variable. This 
is from unit number `r units_merged_beta@data$unit[units_merged_beta@data$allV1 == max(units_merged_beta@data$allV1)]`
Looking at the forest loss layer shows that the unit in question is right at the 
centre of the Pagami Creek fire, which covered almost half of the area of the 
unit. The units significantly impacted by the fire are: 38, 39 and 68 (a small 
corner of unit 67 is also impacted). We should consider leaving out these three 
units. 

Also, unit `r units_merged_beta@data$unit[units_merged_beta@data$forest_point_freq == max(units_merged_beta@data$forest_point_freq)]` has a total of `r max(units_merged_beta@data$forest_point_freq)` 
forested BBA points, compared with the second highest value of `r sort(unique(units_merged_beta@data$forest_point_freq))[length(unique(units_merged_beta@data$forest_point_freq)) - 1]`. 
However, the number of forested BBA points per unit informs us of how precise 
the mean beta value is, so we shouldn't have to worry about it.

2. Check reponse variable for excess of zeros
```{r}
hist(units_merged_beta@data$beta, main = 'Distribution of beta values', xlab = 'Mean beta per unit')
```

We shouldn't have problems here.

3. Colinearity of explanatory variables
```{r, results = 'hide'}
# Functions for printing pair plots 
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y, method="spearman"))
  txt <- format(c(r, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = 1.5)
}
```

```{r, fig.width = 8, fig.height = 8}
# Pair plots of explanatory variables
pairs(units_merged_beta@data[c('tempMN', 'precMN', 'allV1', 'forest_point_freq', 
  'human_footprint')], cex.labels = 1.2, font.labels=1.6, 
  diag.panel=panel.hist, upper.panel= panel.cor)
```

```{r}
source('./Code/HighstatLib.r')
corvif(units_merged_beta@data[c('tempMN', 'precMN', 'allV1', 
  'forest_point_freq', 'human_footprint')])
```

4. Relationships between response and explanatory variables

5. Interactions


##Analyse beta diversity {#analyse_beta_div}
We then continue by starting to construct a model where the response variable is 
mean beta diversity per unit, and the explanatory variables are, for example, 
human footprint, forest loss etc. We also take the number of forest points per 
unit into account as a covariate.

2. Homogeneity of residuals
3. Normaility of residuals

6. Independence of the response variable
Let's see how the semivariance of the residuals change over physical distance. 
```{r}
bird_data_alpha <- dplyr::full_join(unique_coord_id, bird_div_alpha, by = 'ID') %>% 
  filter(!is.na(alpha))
bird_data_gstat <- gstat(id = "alpha", formula = alpha ~ x + y, location = ~ x + y, 
  data = bird_data_alpha)
bird_data_variogram <- variogram(bird_data_gstat, width = ((10000) / 20), 
  cutoff = (10000))
bird_data_variogram
plot(bird_data_variogram, main = 'Semivariogram of bird alpha diversity', 
  xlab = 'Distance (m)')

#mnn_bba_points_nb <- spdep::tri2nb(mnn_bba_points_unique)
#aaa <- sp.correlogram(mnn_bba_points_nb, bird_data_alpha$alpha, order = 30, method = "corr",
#style = "W", randomisation = TRUE, zero.policy = NULL, spChk=NULL)
#moran.test()
```

There seems to be no clear pattern of increasing dissimilarity with distance, in 
fact points very close to each other tend to be less similar to each other than 
points further away from each other.
...to be continued...