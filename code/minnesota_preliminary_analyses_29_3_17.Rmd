---
title: "Preliminary analyses for Minnesota beta diversity"
output:
  pdf_document: default
  html_notebook: default
---

Description: Code for preparing and performing preliminary analysis on Minnesota 
beta diversity  
Author: Eric Le Tortorec  
Date: `r Sys.Date()`  
R version: `r R.Version()$version.string`  

##Table of contents
[Load necessary packages](#load_necessary_packages)  
[Prepare vector data](#prepare_vector_data)  
[Prepare other data](#prepare_other_data)  
[Calculate BBA points per unit](#calcualte_points_per_unit)  
[Create human land-use index with PCA](#human_land_use_pca)  
[Process and calculate human footprint index for each unit](#human_footprint_per_unit)  
[Compare human influence PCA and human footprint](#compare_pca_footprint)  
[Process and calculate forest loss per unit](#forest_loss_per_unit)  
[Prepare bird data](#prepare_bird_data)  
[Calculate alpha diversity](#calculate_alpha_div)  
[Calculate beta diversity](#calculate_beta_div)  

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
# set global chunk options
knitr::opts_knit$set(root.dir = normalizePath('/Users/Eric/Dropbox/Eric/Work/JKL/Theses/Matti_Hakkila/paper_4/'))
```

##Load necessary packages {#load_necessary_packages}
```{r, results = 'hide'}
library(dplyr)
library(tidyr)
library(readxl)
library(maptools)
library(rgeos)
library(rgdal)
library(raster)
library(gstat)
library(psych)
#library(spdep)
```

##Prepare vector data {#prepare_vector_data}
We prepare the vector data by joining all unit-level data together
```{r, results = 'hide'}
# Read the different unit-level shapefiles
units <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units.shp', 'Units')
units_census <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_Census.shp', 'Units_Census')
units_eco_subsection <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_EcoSubsection.shp', 'Units_EcoSubsection')
units_forest_status <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_ForestStatus.shp', 'Units_ForestStatus')
units_land_fire <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_Landfire.shp', 'Units_Landfire')
units_prism <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_PRISM.shp', 'Units_PRISM')
units_road_density <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Units_RoadDensity.shp', 'Units_RoadDensity')
units_forest_loss <- readOGR('./data/forest_loss_3_2017/Units_ForestLoss.shp', 'Units_ForestLoss')

# Join attributes of unit- level shapefiles
units_merged <- units
units_merged <- merge(units_merged, units_eco_subsection, by = 'unit')
units_merged <- merge(units_merged, units_census, by = 'unit')
units_merged <- merge(units_merged, units_prism, by = 'unit')
units_merged <- merge(units_merged, units_forest_status, by = 'unit')
units_merged <- merge(units_merged, units_road_density, by = 'unit')
units_merged <- merge(units_merged, units_land_fire, by = 'unit')
units_merged <- merge(units_merged, units_forest_loss, by = 'unit')
units_merged@data$Dens_Minor <- as.numeric(units_merged@data$Dens_Minor)

# Save the joined data as a shapefile
writeOGR(units_merged, './data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/units_merged.shp', 'units_merged', driver = 'ESRI Shapefile', overwrite_layer = T)
```

We have a total of `r length(units)` units, and the combined unit object has a 
total of `r length(colnames(units_merged@data))` columns. The name and type of 
each column is:
```{r}
sapply(units_merged@data, class)
```

##Prepare other data {#prepare_other_data}
```{r, results = 'hide'}
forest_status_2 <- raster('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/forest_status/forstat_rast2.tif')
land_fire_3 <- raster('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/landfire/landfire3.tif')
units_merged <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/units_merged.shp', 'units_merged')
mnn_bba_points <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/bird_data/MNBBA_Surveys_DominantHabitat_Final.shp', 'MNBBA_Surveys_DominantHabitat_Final')
mnn_bba_points@data$Date <- as.Date(mnn_bba_points@data$Date , "%Y/%m/%d")
```

##Calculate BBA points per unit {#calcualte_points_per_unit}
Later on we will need to determine how many forested BBA points there are per 
unit. There are three ways of doing this, all of which will be performed and 
compared:

* Reclassify the forest status raster into two classes: forest and non-forest
* Reclassify the land_fire_3 raster into the same to classes
* Reclassify the land cover class of each point (this information is included 
in the BBA data) in the same two classes.

The first two approaches perform the reclassification, and then extract raster 
values to points, while the last approach simply reclassifies the assigned land 
cover class for each point.

The reclassifications for the last two approaches are such that forests are:

* Lowland Deciduous Forest
* Northern Hardwoods
* Pine Forest
* Boreal Deciduous
* Oak Forest
* Parkland Deciduous Forest
* Boreal Coniferous
* Lowland Coniferous Forest
* Rural Developed Forest
* Urban Developed Forest
* Pine-Oak Barrens
* Oak Savannah

Let's reclassify the forest_status raster
```{r, eval = FALSE}
reclass_matrix <- matrix(c(0, 3, 1, 5, Inf, 0), ncol = 3, byrow = TRUE)
forest_status_reclass <- reclassify(forest_status_2, reclass_matrix, right = NA)
forest_status_points <- extract(forest_status_reclass, mnn_bba_points)
forest_status_points[is.na(forest_status_points)] <- 0
mnn_bba_points@data$forest_forest_status <- forest_status_points
```

Then the land_fire_3 raster
```{r, eval = FALSE}
reclass_matrix <- matrix(c(2, 3, 0, 4, 8, 1, 9, 18, 0, 
  19, 25, 1, 26, 26, 0, 30, 51, 1), ncol = 3, byrow = TRUE)
land_fire_3_reclass <- reclassify(land_fire_3, reclass_matrix, right = NA)
land_fire_3_points <- extract(land_fire_3_reclass, mnn_bba_points)
land_fire_3_points[is.na(land_fire_3_points)] <- 0
mnn_bba_points@data$forest_land_fire_3 <- land_fire_3_points
```

Finally, we reclassify the Reclass3_5- column from mnna_bba_points (dominant 
landcover type within 50m of the BBA point, using the reclass3 classification)
```{r}
mnn_bba_points@data$forest_bba <- mnn_bba_points@data$Reclass3_5
levels(mnn_bba_points@data$forest_bba) <- list('1' = c("Boreal Coniferous", 
  "Boreal Coniferous_10m", "Boreal Deciduous", "Boreal Deciduous_10m", 
  "Lowland Coniferous Forest", "Lowland Coniferous Forest_10m", 
  "Lowland Deciduous Forest", "Lowland Deciduous Forest_10m", 
  "Northern Hardwoods", "Northern Hardwoods_10m", "Oak Forest", 
  "Oak Forest_10m", "Oak Savannah", "Parkland Deciduous Forest_10m", 
  "Pine Forest", "Pine Forest_10m", "Pine-Oak Barrens", "Pine-Oak Barrens_10m", 
  "Rural Developed Forest_10m", "Urban Developed Forest", 
  "Urban Developed Forest_10m"), '0' = c("Boreal Lowland Grassland", 
  "Boreal Shrub Swamp", "Cropland", "Developed-High Intensity", 
  "Developed-Low Intensity", "Developed-Medium Intensity", "Lowland Herbaceous", 
  "Open Water", "Quarries-Strip Mines-Gravel Pits", "Shrub Swamp", 
  "Upland Grassland", "Upland Native Grassland", "Upland Shrub"))
mnn_bba_points@data$forest_bba <- as.numeric(as.character(mnn_bba_points@data$forest_bba))
```

We then continue by calculating how many unique BBA points fall within each 
unit. It seems like some units are duplicated. We will count how many points 
have duplicated coordinates, and how many have duplicated block_poin values. 
The block_poin values seem like a good candidate for identifying unique points 
since they indicate individual points within blocks.

**Coordinates:**
```{r}
coord_counts <- plyr::count(mnn_bba_points@data, c('x', 'y'))
table(coord_counts$freq)
coord_counts_dupl <- coord_counts[coord_counts$freq > 1, ]
```

We can see that the vast majority of points have uniqe coordinates, a few have 
one duplicate, and one is present three times!

**Block_poin values**
```{r}
block_poin_counts <- plyr::count(mnn_bba_points@data, 'block_poin')
table(block_poin_counts$freq)
block_poin_counts_dupl <- block_poin_counts[block_poin_counts$freq > 1, ]
```

Again, most of the points have unique block_poin values, but quite a few are 
duplicated. Continuing with the block_poin values, we can calculate how far 
apart pairs of points with identical block_poin values are.

```{r}
# All points with duplicated block_poin values
mnn_bba_points_dupl_block_poin <- mnn_bba_points[mnn_bba_points@data$block_poin 
  %in% block_poin_counts_dupl$block_poin, ]
mnn_bba_points_dupl_block_poin <- 
  mnn_bba_points_dupl_block_poin[order(mnn_bba_points_dupl_block_poin@data$block_poin), ]
# Make separate objects for each individual from each pair
mnn_bba_points_dupl_block_poin@data$order <- rep(c(1, 2), 
  length(mnn_bba_points_dupl_block_poin) / 2)
mnn_bba_points_dupl_block_poin_1 <- 
  mnn_bba_points_dupl_block_poin[mnn_bba_points_dupl_block_poin@data$order == 1, ]
mnn_bba_points_dupl_block_poin_2 <- 
  mnn_bba_points_dupl_block_poin[mnn_bba_points_dupl_block_poin@data$order == 2, ]
# Calculate the distance between each pair
dupl_block_poin_pair_distances <- pointDistance(mnn_bba_points_dupl_block_poin_1, 
  mnn_bba_points_dupl_block_poin_2)
dupl_block_poin_pair_distances <- data.frame(distance = dupl_block_poin_pair_distances, 
  block_poin = mnn_bba_points_dupl_block_poin_1@data$block_poin)
dupl_block_poin_pair_distances <- arrange(dupl_block_poin_pair_distances, distance)
summary(dupl_block_poin_pair_distances$distance)
hist(dupl_block_poin_pair_distances$distance, breaks = 50, main = 
    'Frequencies of distances between block_poin pairs', xlab = 
    'Distance between block_poin pairs (m)')
tail(dupl_block_poin_pair_distances, n = 10)
```
From the histogram we can see that most of the distances between pairs of points 
with identical block_poin values are very close to each other. In fact, `r  nrow(dupl_block_poin_pair_distances[dupl_block_poin_pair_distances$distance < 50, ])`
pairs of points have a distance of under 50m, and `r  nrow(dupl_block_poin_pair_distances[dupl_block_poin_pair_distances$distance == 0, ])` points have the 
same coordinates (i.e. a distance of exactly 0). BUT there are a number of 
points with rather large pair-wise distances. These range from several km to 
almost 50km, which means that it makes no sense to remove all duplicate values, 
since we would loose a whole bunch of data. If we leave out the outlying maximum 
value we can see that the mean distance between pairs of duplicates is `r mean(dupl_block_poin_pair_distances$distance[1:157])`m 
and the median is `r  median(dupl_block_poin_pair_distances$distance[1:157])`m. Let's continue 
by inspecting nearest neghbour distances for the whole data.

```{r}
point_dist <- as.data.frame(pointDistance(mnn_bba_points, lonlat = FALSE))
colnames(point_dist) <- mnn_bba_points@data$ID
rownames(point_dist) <- mnn_bba_points@data$ID
# Calcualte minimum distances, but leave zeros out, since they are present in 
# every row and column
point_dist_nn <- sapply(point_dist, FUN = function(x) {min(x[x > 0])})
point_dist_nn <- sort(point_dist_nn)
summary(point_dist_nn)
hist(point_dist_nn, breaks = 20, main = 'Frequencies of nearest neighbour 
  distances between points', 
  xlab = 'Nearest neighbour distance (m)')
```

```{r}
# Delete duplicate coord points
# Plot points located under 50m from each other
point_dist_nn_50m <- data.frame(distance = point_dist_nn[point_dist_nn < 50])
point_dist_nn_50m$ID <- rownames(point_dist_nn_50m)
mnn_bba_points_50m <- mnn_bba_points[mnn_bba_points@data$ID %in% point_dist_nn_50m$ID, ]

```

It's a bit hard to determine a cut-off point since there is a contimuum of 
nearest neighbour values from `r min(point_dist_nn)`m all the way to `r max(point_dist_nn)`m. 
If we look at the smallest distances we can see that there is a small spike at 
the very smallest values (around 10-20m). However, there is a steady stream of 
small frequencies up to 200m. This is a bit odd considering that we would expect 
a smallish frequency of very small distances (points that have been counted 
twice), a gap, and then clearly larger distances between independent points.
```{r}
hist(point_dist_nn[1:1000], breaks = 20, main = 'Frequencies of nearest neighbour 
  distances between points', xlab = 'Nearest neighbour distance (m)')
```

Later on, in the [preparation of the bird data](#prepare_bird_data) we plot a semivariogram, 
but it does not show any clear distance within which BBA points are similar, so 
we will continue for time being by simply removing points with duplicate 
coordinates, keeping the earliest observations.

```{r}
# Select unique points based on coordinates
#mnn_bba_points_unique <- mnn_bba_points[which(!duplicated(mnn_bba_points@data$block_poin)), ]
mnn_bba_points_unique <- mnn_bba_points[order(mnn_bba_points@data$x, 
  mnn_bba_points@data$y, mnn_bba_points@data$Date), ]
mnn_bba_points_unique <- mnn_bba_points_unique[which(!duplicated(mnn_bba_points_unique@data[c('x', 'y')], fromLast = FALSE)), ]
#head(mnn_bba_points_unique@data[c('Date', 'unit')], n = 30)

# Calculate the number of unique BBA points within each unit
units_points <- over(mnn_bba_points_unique, units_merged)
units_points_count <- data.frame(table(units_points$unit))
colnames(units_points_count) <- c('unit', 'point_freq')
units_points_count$unit <- as.numeric(as.character(units_points_count$unit))
units_merged <- merge(units_merged, units_points_count, by = 'unit')
units_merged@data$point_freq[is.na(units_merged@data$point_freq)] <- 0

# Summarise how many unique BBA points units have
point_freq <- as.data.frame(table(units_merged@data$point_freq))
colnames(point_freq) <- c('points per unit', 'freq')
print.data.frame(point_freq)
hist(units_merged@data$point_freq, breaks = 18, xlim = c(0, 20), xlab = 'Number 
of BBA points', main = 'BBA points per unit')
```

There are a total of `r length(mnn_bba_points_unique)` unique points out of a 
total of `r length(mnn_bba_points)` BBA points in the data. The number of unique 
forested BBA points dependes on the reclassification method:

* Reclassifying the forest_status raster results in 2076 unique points
* Reclassyfying the land_fire_3 raster results in 2054 points
* Reclassifying the dominant land cover class within 50m of BBA points results in `r sum(mnn_bba_points_unique@data$forest_bba)` points

Even though reclassifying the dominant land cover class of the BBA points yields 
the least points, we will use it since it has been measured directly in the 
field. Using this approach, we then calculate the number of forested BBA points 
per unit.
```{r}
# Select forest BBA points according to the forest reclassification approaches
#mnn_bba_points_forest_forest_status <- mnn_bba_points_unique[mnn_bba_points_unique@data$forest_forest_status == 1, ]
#mnn_bba_points_forest_land_fire_3 <- mnn_bba_points_unique[mnn_bba_points_unique@data$forest_land_fire_3 == 1, ]
mnn_bba_points_forest <- mnn_bba_points_unique[mnn_bba_points_unique@data$forest_bba == 1, ]

# Calculate the number of BBA points in forested pixels within each unit
units_forest_points <- over(mnn_bba_points_forest, units_merged)
units_forest_points_count <- data.frame(table(units_forest_points$unit))
colnames(units_forest_points_count) <- c('unit', 'forest_point_freq')
units_forest_points_count$unit <- as.numeric(as.character(units_forest_points_count$unit))

units_merged <- merge(units_merged, units_forest_points_count, by = 'unit')
units_merged@data$forest_point_freq[is.na(units_merged@data$forest_point_freq)] <- 0

# Summarise how many unique forested BBA points there are per unit
forest_point_freq <- as.data.frame(table(units_merged@data$forest_point_freq))
colnames(forest_point_freq) <- c('forested points per unit', 'freq')
print.data.frame(forest_point_freq)
hist(units_merged@data$forest_point_freq, breaks = 15, xlim = c(0, 15), xlab = 'Number 
of forested BBA points', main = 'Forested BBA points per unit')
```
We can see that with a minimum of 2 BBA points in forested pixels per unit, we 
have a total of `r nrow(units_merged[units_merged@data$forest_point_freq >= 2, ])` units.

##Create human land-use index with PCA {#human_land_use_pca}
Let's begin by selecting land-use variables that describe human land-use. We 
want to study if human land-use causes biotic homogenisation. We can select the 
following variables from the merged unit data:

* sum of people per unit
* density of major highways per unit
* density of minor highways per unit
* density of other roads per unit
* proportion of quarries, strip mines and gravel pits
* proportion of low intensity development
* proportion of medium intensity development
* proportion of high intensity development
* proportion of cropland

```{r}
# Select variables for PCA
units_merged_pca <- dplyr::select(units_merged@data, censusSUM, Dens_Major, 
  Dens_Minor, Dens_Other, HabV15:HabV18, HabV26)

# Print scree plot, showing how many components to include in the PCA
VSS.scree(units_merged_pca, main = "scree plot")
```

2 or 3 components should be enough, let's perform the PCA and extract 3 factors
```{r}
# Perform PCA
human_gradient_pca <- principal(units_merged_pca, nfactors = 3, rotate="varimax",
  covar = F)
human_gradient_pca
```

We can see that the first principal component is highly correlated with 
population number, density of major highways and other roads, proportion of low 
intensity development, proportion of medium intensity development and proportion 
of high intensity development. The second principal component is correlated with 
the density of minor highways and croplands, and the third principal component 
with the proportion of quarries, strip mines and gravel pits.

The first component does a good job of summarising many aspects of human 
land-use, and captures 58% of the variation, while the next two are more 
specific and capture 12% of the variation, respectively.

Let's join the first component to the merged data
```{r}
units_merged@data$human_pca <- human_gradient_pca$scores[, 1]
```

##Process and calculate human footprint index for each unit {#human_footprint_per_unit}
We continue by looking into calculating an index describing the intensity of 
the human footprint.

Then we read, clip and reproject the human footprint data so that average values 
per unit can be calculated. The first part of the code below reads, clips and 
reprojects the human footprint data. For some reason raster::projectRaster 
cannot reproject between WGS84 and UTM zone 15, even if the raster has been 
clipped to the spatial limits of zone 15. Thus, the clipped raster is saved as 
a geotiff, and reprojected with gdal in the terminal.
```{r, eval = FALSE}
minnesota <- readOGR('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/units_spatial_data/Minnesota_Outline.shp', 'Minnesota_Outline')
human_footprint_orig <- raster('./data/last_of_the_wild/human_footprint_2/hfp_n_amer/dblbnd.adf')
crs(human_footprint_orig) <- CRS("+init=epsg:4326")

minnesota_extent <- as(extent(minnesota), 'SpatialPolygons')
crs(minnesota_extent) <- crs(minnesota)

minnesota_extent_wgs84 <- spTransform(minnesota_extent, CRS = CRS('+init=epsg:4326'))
human_footprint_minnesota <- crop(human_footprint_orig, minnesota_extent_wgs84)

writeRaster(human_footprint_minnesota, filename = './Data/last_of_the_wild/human_footprint_2/human_footprint_minnesota.tif', overwrite =T)
gdalwarp -s_srs '+init=epsg:4326' -t_srs '+init=epsg:26915' human_footprint_minnesota.tif human_footprint_utm15n.tif
```

We then read the reprojected data and calculate the average human footprint 
value per unit, and merge it to the unit-level data
```{r}
human_footprint <- raster('./data/last_of_the_wild/human_footprint_2/human_footprint_utm15n.tif')
units_hfp <- extract(human_footprint, units, fun = mean, na.rm = T)
units_hfp <- data.frame(unit = seq(1, 617, 1), human_footprint = units_hfp)
units_merged <- merge(units_merged, units_hfp, by = 'unit')
```

##Compare human influence PCA and human footprint {#compare_pca_footprint}
Before comparing the pca and human footprint values we choose only units with 
at least two forested BBA points.
```{r, results = 'hide'}
# Select units that have at least 2 forested unique BBA points in them
min_points <- 2
units_merged_subset <- units_merged[units_merged@data$forest_point_freq >= min_points, ]
```

Then, we print a scatter plot of pca vs. human footprint.
```{r}
plot(units_merged_subset$human_pca, units_merged_subset$human_footprint, xlab = 
    'Human influence principal component', ylab = 'Human footprint index')
```

Not bad! We have a Pearson's correlation coefficient of `r cor(units_merged_subset$human_pca, units_merged_subset$human_footprint, use = 'complete.obs')`, which means that the two 
indices pretty much capture the same variation in the data. Furthermore, if we 
leave out the outlier the correlation coefficient rises to `r cor(units_merged_subset$human_pca[units_merged_subset$human_pca < 8], units_merged_subset$human_footprint[units_merged_subset$human_footprint < 80], use = 'complete.obs')`
It would probably be a good idea to go with the human footprint index even 
though its time period does not match the bird data so well (1995 - 2004). The 
roads, railways, population etc. included in the calculation of the index are 
probably variables that won't change very quickly. In any case, the variables 
used in the PCA are not necessarily up to date with the bird data either.

##Process and calculate forest loss per unit {#forest_loss_per_unit}
In addition to the index describing human land use we want to study if forest 
loss has an impact on beta diversity. We have forest loss data from Minnesota, 
which is derived from Hansen et al. 2013 (Science). The data has proportion 
forest loss between 2001-2014 per unit. Note that forest fires are also 
included! Ed said that data separating the two types of forest loss 
might be available in 6 months - 1 year, but this is too long. Let's use the 
data we have available and see if forest loss is correlated with human pressure.
```{r}
plot(units_merged_subset$human_footprint, units_merged_subset$allV1, ylab = 
    'Proportion forest loss 2001-2014', xlab = 'Human footprint index')
```

It seems ok. There is a slight negative trend, but nothing super clear. The 
Pearson's correlation coefficient is `r cor(units_merged_subset$human_footprint, units_merged_subset$allV1, use = 'complete.obs')`.

##Prepare bird data {#prepare_bird_data}
Let's continue by loading the bird data and printing all unique bird species in 
the data.
```{r}
library(readxl)
bird_data_whole <- read_excel('./data/minnesota_bird_data/mnbba_homogenization_data_9_22_2015/bird_data/Homogenization_All_BirdData.xlsx')
sort(unique(bird_data_whole$common))
```

We filter the bird data so that we only include BBA points with unique 
coordinates, and leave out all unidentified species. We then calculate the 
alpha diversity for each BBA point.
```{r}
unique_coord_id <- mnn_bba_points_unique@data[c('ID', 'x', 'y')]

bird_points_species <- dplyr::select(bird_data_whole, ID, common, Sum_AllBirds) %>% 
  dplyr::filter(!grepl('Unidentified', common)) %>% 
  dplyr::filter(ID %in% unique_coord_id$ID) %>%
  dplyr::arrange(ID, common)

bird_points_species_wide <- spread(bird_points_species, ID, Sum_AllBirds)
bird_points_species_wide[is.na(bird_points_species_wide)] <- 0
bird_points_species_wide <- as.data.frame(bird_points_species_wide)
rownames(bird_points_species_wide) <- bird_points_species_wide$common
bird_points_species_wide <- bird_points_species_wide[2:ncol(bird_points_species_wide)]
```

##Calculate alpha diversity {#calculate_alpha_div}
Next we calculate alpha diversity of BBA points with the Rao quadratic entropy 
index. The Jost correction is used to correct lower than expected beta diversity 
values. We us the the Rao function, written by Francesco Bello et al. *  
*De Bello F, Lavergne S, Meynard CN, Lepš J, Thuiller W. The partitioning of 
diversity: showing Theseus a way out of the labyrinth: Theseus and the 
partitioning of diversity. Journal of Vegetation Science. 2010;21(5):992–1000.
```{r}
# It seems like the functional and phylogenetic matrices are compulsory. At this 
# point we don't have such things, so I created empty matrices to get the 
# script to work.
funct_matrix <- matrix(data = 0, nrow = nrow(bird_points_species_wide), 
  ncol = nrow(bird_points_species_wide))
phylo_matrix <- matrix(data = 0, nrow = nrow(bird_points_species_wide), 
  ncol = nrow(bird_points_species_wide))

source("./Code/Rao.r")
bird_div <- Rao(sample = bird_points_species_wide, dfunc = funct_matrix, 
  dphyl = phylo_matrix, weight = FALSE, Jost = TRUE, structure = NULL)
#bird_div_beta_add <- as.data.frame(as.matrix(bird_div$TD$Pairwise_samples$Beta_add))
#bird_div_beta_prop <- as.data.frame(as.matrix(bird_div$TD$Pairwise_samples$Beta_prop))
#bird_div_beta_add[1:10, 1:8]
#bird_div_beta_prop[1:10, 1:8]
bird_div_alpha <- data.frame(alpha = bird_div$TD$Alpha)
bird_div_alpha$ID <- as.integer(rownames(bird_div_alpha))
```

Perhaps plotting a semivariogram can help use decide if there is a minimum 
nearest neighbour distance within which BBA points are alike? Let's see how the 
semivariance of alpha diversity changes over physical distance. We'll 
concentrate on distances up to 1.2km, the mean nearest neighbour distance 
between BBA points.
```{r}
bird_data_alpha <- dplyr::full_join(unique_coord_id, bird_div_alpha, by = 'ID')

bird_data_gstat <- gstat(id = "alpha", formula = alpha ~ x + y, location = ~ x + y, 
  data = bird_data_alpha)
bird_data_variogram <- variogram(bird_data_gstat, width = ((1200) / 11), 
  cutoff = (1200))
bird_data_variogram
plot(bird_data_variogram, main = 'Semivariogram of bird alpha diversity', 
  xlab = 'Distance (m)')

#mnn_bba_points_nb <- spdep::tri2nb(mnn_bba_points_unique)
#aaa <- sp.correlogram(mnn_bba_points_nb, bird_data_alpha$alpha, order = 30, method = "corr",
#style = "W", randomisation = TRUE, zero.policy = NULL, spChk=NULL)
#moran.test()
```

There seems to be no clear pattern of increasing dissimilarity with distance, in 
fact points very close to each other tend to be less similar to each other than 
points up to 700m from each other.

##Calculate beta diversity {#calculate_beta_div}
The next step is writing a loop to calculate beta diversity between forested 
BBA points within each unit that contains at least 2 such points.

...to be continued...